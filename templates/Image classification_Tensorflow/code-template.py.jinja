# Before running, install required packages:
{% if notebook %}

!
{%- else %}
#
{%- endif %}
 pip install numpy tensorflow{% if visualization_tool == "comet.ml" %} comet_ml{% endif %}

{% if notebook %}


# ---
{% endif %}

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image_dataset_from_directory
{% if data_format == "Image files" %}
import urllib
import zipfile
{% endif %}
{% if visualization_tool == "Tensorboard" or checkpoint %}
from datetime import datetime
{% endif %}
{% if checkpoint %}
from pathlib import Path
{% endif %}

{% if data_format == "Numpy arrays" %}
def fake_data():
    # 4 images of shape 1x16x16 with labels 0, 1, 2, 3
    return [np.random.rand(4, 1, 16, 16), np.arange(4)]

{% elif data_format == "Image files" %}


# COMMENT THIS OUT IF YOU USE YOUR OWN DATA.
# Download example data into ./data/image-data (4 image files, 2 for "dog", 2 for "cat").
url = "https://github.com/jrieke/traingenerator/raw/main/data/fake-image-data.zip"
zip_path, _ = urllib.request.urlretrieve(url)
with zipfile.ZipFile(zip_path, "r") as f:
    f.extractall("data")

{% endif %}

{{ header("Setup") }}
{% if data_format == "Numpy arrays" %}
# INSERT YOUR DATA HERE
# Expected format: [images, labels]
# - images has array shape (num samples, color channels, height, width)
# - labels has array shape (num samples, )
train_data = fake_data()  # required
val_data = fake_data()    # optional
test_data = None          # optional
{% elif data_format == "Image files" %}
# INSERT YOUR DATA HERE
# Expected format: One folder per class, e.g.
# train
# --- dogs
# |   +-- lassie.jpg
# |   +-- komissar-rex.png
# --- cats
# |   +-- garfield.png
# |   +-- smelly-cat.png
#
# Example: https://github.com/jrieke/traingenerator/tree/main/data/image-data
train_data = "data/image-data"  # required
val_data = "data/image-data"    # optional
test_data = None                # optional
{% endif %}

# Set up hyperparameters.
lr = {{ lr }}
batch_size = {{ batch_size }}
num_epochs = {{ num_epochs}}

{# TODO Add Image_Size #}
img_size = (224,224)
img_shape = img_size + (3,)

# Set up logging.

{% if visualization_tool == "Tensorboard" or checkpoint %}
experiment_id = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
{% endif %}
{% if visualization_tool == "Tensorboard" %}
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=experiment_id, histogram_freq=1)
{% endif %}
{% if visualization_tool == "comet.ml" %}
experiment = Experiment("{{ comet_api_key }}"{% if comet_project %}, project_name="{{ comet_project }}"{% endif %})
{% endif %}
{% if checkpoint %}
checkpoint_dir = tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/{experiment_id}/model.{epoch:02d}-{val_loss:.2f}.h5')
{% endif %}
print_every = {{ print_every }}  # batches

{{ header("Preprocessing") }}
def preprocess(data, name):
    if data is None:  # val/test can be empty
        return None
        
    {% if data_format == "Image files" %}
    # Read image files to tensorflow dataset.
    dataset = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20, horizontal_flip=True)
    loader = dataset.flow_from_directory(data, target_size=img_size)
    {# TODO: Add more data_augmentation #}
    {% elif data_format == "Numpy arrays" %}
    images, labels = data

    # Rescale images to 0-255 and convert to uint8.
    # Note: This is done for each dataset individually, which is usually ok if all 
    # datasets look similar. If not, scale all datasets based on min/ptp of train set.
    images = (images - np.min(images)) / np.ptp(images) * 255
    images = images.astype(np.uint8)

    # If images are grayscale, convert to RGB by duplicating channels.
    if images.shape[1] == 1:
        images = np.stack((images[:, 0],) * 3, axis=1)
    )

    {# This code could be improved #}
    Pil_image = []

    for i  in range(len(data[0])):
        Pil_image.append(tf.keras.preprocessing.image.array_to_img(images[i],data_format ="channels_first"))
        Pil_image[i] = Pil_image[i].resize((224,224)
        Pil_image[i] = tf.keras.preprocessing.image.img_to_array(Pil_image[i])
    
    loader = tf.convert_to_tensor(Pil_image)
    {% endif %}

    return loader

train_loader = preprocess(train_data, "train")
val_loader = preprocess(val_data, "val")
test_loader = preprocess(test_data, "test")

{{ header("Model") }}

model = tf.keras.applications.MobileNetV2(input_shape=img_shape,
                                               include_top=True,
                                               weights='imagenet', classes=1000)


model.trainable = True  

model.compile(optimizer = tf.keras.optimizers.{{ optimizer }}(lr={{lr}}),
              loss = "{{ loss }}",
              metrics = ["accuracy"])

model.fit(train_loader,
        batch_size={{batch_size}},
        epochs={{num_epochs}},
        validation_data=val_loader
        {% if visualization_tool == "Tensorboard" and checkpoint%}
        ,callbacks = [tensorboard_callback, checkpoint_dir]
        {% elif checkpoint %}
        ,callbacks = [checkpoint_dir]
        {% elif visualization_tool == "Tensorboard" %}
        ,callbacks = [tensorboard_callback]
        {% endif %}
        )
